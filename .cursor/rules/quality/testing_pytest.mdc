---
description:
globs:
alwaysApply: false
---
# Testing with Pytest

## Objective
To ensure comprehensive test coverage, maintainable test suites, and effective use of Pytest features for both unit and integration testing.

## Context
- **Technologies**: Pytest, Python 3.13+
- **Tools**: `pytest-asyncio` (for async tests), `pytest-mock` (for mocking), `pytest-cov` (for coverage), `pytest-xdist` (for parallel execution), `pytest-databases`.
- **Project Files**: `src/py/tests/`, `tests/`. `pyproject.toml` contains Pytest configuration (`tool.pytest.ini_options`).

## Rules

### Test Structure and Naming
- **File Naming**: Test files should be named `test_*.py` or `*_test.py` (prefer `test_*.py`).
- **Function Naming**: Test functions should be named `test_*` and clearly describe the scenario and expected outcome.
    - ✅ `def test_create_user_with_valid_data_returns_201_and_user_object():`
    - ❌ `def test_user():`
- **Class Naming**: Test classes (if used for grouping related tests) should be named `Test*`.
    - ✅ `class TestUserService:`
- **Organization**:
    - `src/py/tests/unit/`: For unit tests, testing individual modules/functions/classes in isolation. Mocks are heavily used here.
    - `src/py/tests/integration/`: For integration tests, testing interactions between components (e.g., API endpoints with database and services).
- **Markers**: Use Pytest markers (`@pytest.mark.<marker_name>`) to categorize tests (e.g., `unit`, `integration`, `slow`). Markers are defined in `pyproject.toml`.
    - ✅ `@pytest.mark.integration`

### Test Content
- **AAA Pattern (Arrange, Act, Assert)**: Structure tests clearly using the Arrange, Act, Assert pattern.
    - ✅
      ```python
      async def test_get_item_success(item_id: UUID, client: AsyncTestClient, item_in_db: Item):
          # Arrange (often handled by fixtures)
          # item_id and item_in_db are provided by fixtures.
          # client is the AsyncTestClient for making requests.

          # Act
          response = await client.get(f"/items/{item_id}")

          # Assert
          assert response.status_code == 200
          response_data = response.json()
          assert response_data["id"] == str(item_id)
          assert response_data["name"] == item_in_db.name
      ```
- **Single Responsibility**: Each test should ideally verify one specific behavior or outcome.
- **Independence**: Tests must be independent and not rely on the state or outcome of other tests. Use fixtures for setup and teardown.
- **Mocking (`pytest-mock`)**: Use the `mocker` fixture from `pytest-mock` for mocking external dependencies or specific internal calls in unit tests. Avoid over-mocking.
    - ✅ `mocker.patch('app.services.some_service.some_object.external_call', return_value=...)`
- **Fixtures**: Utilize Pytest fixtures (`@pytest.fixture`) for setting up preconditions (e.g., test data, client instances, database sessions) and cleaning up resources.
    - Define reusable fixtures in `conftest.py` files at appropriate directory levels.
    - Scope fixtures correctly (`function`, `class`, `module`, `session`).
    - ✅
      ```python
      # src/py/tests/conftest.py
      import pytest_asyncio
      from httpx import AsyncClient
      from litestar import Litestar
      from sqlalchemy.ext.asyncio import AsyncSession

      @pytest_asyncio.fixture(scope="function")
      async def db_session(app: Litestar) -> AsyncSession: ...

      @pytest_asyncio.fixture(scope="function")
      async def client(app: Litestar) -> AsyncClient: ...
      ```

### Assertions
- **Specific Assertions**: Use specific assertion functions (e.g., `assert a == b`, `assert a is True`, `assert a in b`, `assert isinstance(a, Type)`) rather than generic `assert True`.
- **Helper Assertions**: For complex objects or common assertion patterns, consider creating helper assertion functions.
- **Descriptive Failure Messages**: Pytest often provides good introspection on failure. Add custom messages to assertions (`assert a == b, "Custom failure message"`) only if the default output is genuinely unclear.

### Asynchronous Tests (`pytest-asyncio`)
- **`async def`**: Mark async test functions with `async def`.
- **Async Fixtures**: Use `@pytest_asyncio.fixture` for fixtures that need to perform async operations.

### Integration Tests
- **`AsyncTestClient`**: Use Litestar's `AsyncTestClient` (usually via `httpx.AsyncClient` pointed at the app) for testing HTTP endpoints.
- **Database State**: Manage database state carefully. `pytest-databases` plugin helps manage this. Tests should clean up after themselves, typically via transaction rollback managed by fixtures.
- **Real Dependencies**: Integration tests should use real database connections and other in-process services where feasible. Mock external third-party services (e.g., payment gateways, external APIs not part of the SUT).

### Coverage (`pytest-cov`)
- **Aim for High Coverage**: Strive for high test coverage. `make coverage` command (from `Makefile`) generates reports.
- **Meaningful Tests**: Focus on writing meaningful tests that verify behavior and edge cases, not just achieving a high coverage percentage with trivial tests.
- **Exclusions**: Coverage exclusions are defined in `pyproject.toml` (`tool.coverage.report.exclude_lines` and `tool.coverage.run.omit`).

## Exceptions
- Some End-to-End (E2E) tests (if written) might require more complex setup or less isolation if they are testing full user flows across different services.
- Performance-specific tests might have different structures and assertion patterns.
